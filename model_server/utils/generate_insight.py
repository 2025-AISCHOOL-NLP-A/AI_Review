import os
import json
from datetime import datetime
from dotenv import load_dotenv
from utils.db_connect import get_connection
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

load_dotenv()

"""
êµ¬ì¡°:

fetch_review_data() - DBì—ì„œ ë¦¬ë·° ë°ì´í„° ì¡°íšŒ
build_analysis_prompt() - ì¸ì‚¬ì´íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
generate_insight_with_llm() - LangChainìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
save_insight_to_db() - ì¸ì‚¬ì´íŠ¸ DB ì €ì¥
generate_insight_from_db() - ë©”ì¸ í•¨ìˆ˜ (ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰)
"""

# ===========================
# 1ï¸âƒ£ ë°ì´í„° ì¡°íšŒ
# ===========================
def fetch_review_data(product_id: int) -> dict:
    """
    ì œí’ˆì˜ ë¦¬ë·° ë°ì´í„° ì¡°íšŒ
    - ì „ì²´ ë¦¬ë·° ìˆ˜
    - í‚¤ì›Œë“œë³„ ê¸ì •/ë¶€ì • ì§‘ê³„
    - ìƒ˜í”Œ ë¦¬ë·° (ìµœê·¼ 200ê°œ)
    """
    conn = get_connection()
    try:
        cursor = conn.cursor()
        
        # 1. ì „ì²´ ë¦¬ë·° ìˆ˜
        cursor.execute(
            "SELECT COUNT(*) AS total_reviews FROM tb_review WHERE product_id = %s",
            (product_id,)
        )
        total_data = cursor.fetchone()
        total_reviews = int(total_data["total_reviews"]) if total_data else 0
        
        # 2. í‚¤ì›Œë“œë³„ ê°ì„± ì§‘ê³„
        cursor.execute(
            """
            SELECT 
                k.keyword_text,
                SUM(CASE WHEN ra.sentiment = 'positive' THEN 1 ELSE 0 END) AS positive,
                SUM(CASE WHEN ra.sentiment = 'negative' THEN 1 ELSE 0 END) AS negative
            FROM tb_reviewAnalysis ra
            JOIN tb_keyword k ON k.keyword_id = ra.keyword_id
            JOIN tb_review r ON r.review_id = ra.review_id
            WHERE r.product_id = %s
            GROUP BY k.keyword_id, k.keyword_text
            ORDER BY (positive + negative) DESC
            """,
            (product_id,)
        )
        sentiment_data = cursor.fetchall()
        
        # 3. ìƒ˜í”Œ ë¦¬ë·° (ìµœê·¼ 200ê°œ)
        cursor.execute(
            """
            SELECT review_text 
            FROM tb_review 
            WHERE product_id = %s 
            ORDER BY review_date DESC 
            LIMIT 200
            """,
            (product_id,)
        )
        reviews_data = cursor.fetchall()
        
        # ë°ì´í„° êµ¬ì¡°í™”
        sentiment_summary = {
            item["keyword_text"]: {
                "positive": int(item["positive"]),
                "negative": int(item["negative"])
            }
            for item in sentiment_data
        }
        
        sample_reviews = [r["review_text"] for r in reviews_data]
        
        return {
            "total_reviews": total_reviews,
            "sentiment_summary": sentiment_summary,
            "sample_reviews": sample_reviews
        }
        
    finally:
        conn.close()


# ===========================
# 2ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ìƒì„±
# ===========================
def build_analysis_prompt(data: dict) -> str:
    """ì¸ì‚¬ì´íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""ë‹¹ì‹ ì€ ê³ ê° ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë¦¬ë·° ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë¨¼ì € **ê¹Šì´ ìˆëŠ” ë‚´ë¶€ ë¶„ì„**ì„ ìˆ˜í–‰í•œ ë’¤,
ê·¸ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì •ì œëœ ê°„ëµ ìš”ì•½(summary)**ì„ í•¨ê»˜ ì‘ì„±í•˜ì„¸ìš”.

ë¦¬ë·° ë°ì´í„°:
{json.dumps(data, ensure_ascii=False, indent=2)}

ì¶œë ¥ì€ ì•„ë˜ JSON êµ¬ì¡°ë¥¼ **ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”**:
{{
  "summary": {{
    "keywords": {{
      "positive": ["ê¸ì • í‚¤ì›Œë“œ1", "ê¸ì • í‚¤ì›Œë“œ2", ...],
      "negative": ["ë¶€ì • í‚¤ì›Œë“œ1", "ë¶€ì • í‚¤ì›Œë“œ2", ...]
    }},
    "insight_one_liner": "ì „ì²´ ë¦¬ë·°ë¥¼ í•œ ì¤„ë¡œ ìš”ì•½í•œ ë¬¸ì¥ (ì§§ê³  ëª…í™•í•˜ê²Œ)",
    "recommendation": "ê°€ì¥ ì¤‘ìš”í•œ ê°œì„  ì œì•ˆ (ê°„ê²°í•˜ê²Œ)"
  }},
  "report": {{
    "title": "ğŸ“Š ë¦¬ë·° ë¶„ì„ ë³´ê³ ì„œ",
    "sentiment_ratio": "ê¸ì •: 70%, ë¶€ì •: 30%",
    "positive_points": ["ê³ ê°ì´ ë†’ê²Œ í‰ê°€í•œ ìš”ì¸ë“¤ì„ ë¬¸ì¥ ì¤‘ì‹¬ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…"],
    "negative_points": ["ë¶ˆë§Œ ìš”ì¸ ë° êµ¬ì²´ì  ìƒí™©ì„ ìƒì„¸íˆ ë¶„ì„"],
    "improvement_suggestions": ["êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì œì•ˆ"],
    "overall_summary": "ì „ì²´ ì—¬ë¡ ê³¼ íŠ¸ë Œë“œë¥¼ ê¹Šì´ ìˆê²Œ ì •ë¦¬"
  }}
}}

ì‘ì„± ë‹¨ê³„ ì§€ì¹¨:
1ï¸âƒ£ ë‚´ë¶€ì ìœ¼ë¡œ ì¶©ë¶„íˆ ìƒê°í•˜ê³ , ìƒì„¸í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ì„¸ìš”.
2ï¸âƒ£ `report`ëŠ” ë¶„ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê¸¸ê²Œ, ë…¼ë¦¬ì ì´ê³  ê·¼ê±° ìˆëŠ” ì„¤ëª…ì„ í¬í•¨í•˜ì„¸ìš”.
3ï¸âƒ£ `summary`ëŠ” reportì˜ ìš”ì ì„ ì••ì¶•í•´ ê°„ê²°í•œ í‘œí˜„ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
4ï¸âƒ£ ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ í•˜ì„¸ìš”."""


# ===========================
# 3ï¸âƒ£ LLM í˜¸ì¶œ
# ===========================
def generate_insight_with_llm(prompt: str) -> dict:
    """LangChainìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    try:
        # OpenAI API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            max_tokens=10000
        )
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë¦¬ë·° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í†µì°°ë ¥ ìˆëŠ” ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”."),
            HumanMessage(content=prompt)
        ]
        
        # LLM í˜¸ì¶œ
        print("ğŸ¤– LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
        response = llm.invoke(messages)
        
        # ì‘ë‹µ ë‚´ìš© ì •ë¦¬ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        content = response.content.strip()
        
        # ```json ... ``` í˜•íƒœë¡œ ê°ì‹¸ì ¸ ìˆìœ¼ë©´ ì œê±°
        if content.startswith("```json"):
            content = content[7:]  # ```json ì œê±°
        elif content.startswith("```"):
            content = content[3:]  # ``` ì œê±°
        
        if content.endswith("```"):
            content = content[:-3]  # ``` ì œê±°
        
        content = content.strip()
        
        # JSON íŒŒì‹±
        result = json.loads(content)
        print("âœ… ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ")
        
        return result
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"ì‘ë‹µ ë‚´ìš©: {response.content}")
        raise
    except Exception as e:
        print(f"âŒ LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        raise


# ===========================
# 4ï¸âƒ£ DB ì €ì¥
# ===========================
def save_insight_to_db(product_id: int, user_id: int, insight_data: dict) -> int:
    """
    ì¸ì‚¬ì´íŠ¸ ë°ì´í„°ë¥¼ DBì— ì €ì¥
    Returns: insight_id
    """
    conn = get_connection()
    try:
        cursor = conn.cursor()
        
        # ë°ì´í„° ì¶”ì¶œ
        summary = insight_data.get("summary", {})
        pos_keywords = ", ".join(summary.get("keywords", {}).get("positive", []))
        neg_keywords = ", ".join(summary.get("keywords", {}).get("negative", []))
        insight_summary = summary.get("insight_one_liner", "")
        improvement_suggestion = summary.get("recommendation", "")
        content_json = json.dumps(insight_data.get("report", {}), ensure_ascii=False)
        
        # INSERT ì¿¼ë¦¬
        cursor.execute(
            """
            INSERT INTO tb_productInsight (
                product_id,
                user_id,
                pos_top_keywords,
                neg_top_keywords,
                insight_summary,
                improvement_suggestion,
                content,
                created_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """,
            (
                product_id,
                user_id,
                pos_keywords,
                neg_keywords,
                insight_summary,
                improvement_suggestion,
                content_json,
                datetime.now()
            )
        )
        
        # insight_id ê°€ì ¸ì˜¤ê¸°
        insight_id = cursor.lastrowid
        
        print(f"âœ… tb_productInsightì— ì €ì¥ ì™„ë£Œ (insight_id={insight_id})")
        
        return insight_id
        
    finally:
        conn.close()


# ===========================
# ğŸ¯ ë©”ì¸ í•¨ìˆ˜
# ===========================
def generate_insight_from_db(product_id: int, user_id: int = None) -> int:
    """
    ì œí’ˆ ë¦¬ë·° ì¸ì‚¬ì´íŠ¸ ìƒì„± ë©”ì¸ í•¨ìˆ˜
    
    Args:
        product_id: ì œí’ˆ ID
        user_id: ì‚¬ìš©ì ID (ì„ íƒ, ì—†ìœ¼ë©´ None)
    
    Returns:
        insight_id: ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸ ID
    """
    try:
        print(f"ğŸ” ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘ (product_id={product_id})")
        
        # 1. ë°ì´í„° ì¡°íšŒ
        print("ğŸ“Š ë¦¬ë·° ë°ì´í„° ì¡°íšŒ ì¤‘...")
        data = fetch_review_data(product_id)
        
        if data["total_reviews"] == 0:
            print("âš ï¸ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"âœ… ë¦¬ë·° {data['total_reviews']}ê°œ ì¡°íšŒ ì™„ë£Œ")
        
        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = build_analysis_prompt(data)
        
        # 3. LLM í˜¸ì¶œ
        insight = generate_insight_with_llm(prompt)
        
        # 4. DB ì €ì¥
        insight_id = save_insight_to_db(product_id, user_id, insight)
        
        print(f"ğŸ‰ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ (insight_id={insight_id})")
        
        return insight_id
        
    except Exception as e:
        print(f"âŒ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


# ===========================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# ===========================
if __name__ == "__main__":
    from utils.db_connect import init_db_pool, close_db_pool
    
    # í…ŒìŠ¤íŠ¸ìš©
    product_id = 1012
    user_id = 10001
    
    try:
        # DB Pool ì´ˆê¸°í™”
        print("ğŸ”§ DB Connection Pool ì´ˆê¸°í™” ì¤‘...")
        init_db_pool()
        
        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insight_id = generate_insight_from_db(product_id, user_id)
        
        if insight_id:
            print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ! insight_id={insight_id}")
        else:
            print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    
    finally:
        # DB Pool ì •ë¦¬
        print("\nğŸ§¹ DB Connection Pool ì •ë¦¬ ì¤‘...")
        close_db_pool()
