import re
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from app.models import ModelRegistry
from .keywords import BOOST_KEYWORDS, NEG_TRIGGERS
import json, os

CONFIG_PATH = os.path.join(os.path.dirname(__file__), "config.json")
cfg = json.load(open(CONFIG_PATH, encoding="utf-8"))
ASPECTS = cfg["aspect_labels"]

# =========================================================
# 1ï¸âƒ£ ë¬¸ì¥ ë¶„ë¦¬ (ì ‘ì†ì‚¬ í¬í•¨)
# =========================================================
def split_sentences(text):
    text = re.sub(r"([^.?!]*?)(?:ì§€ë§Œ|ê·¸ëŸ¬ë‚˜|í•˜ì§€ë§Œ|ë°˜ë©´ì—)\s*", r"\1. ", text)
    sentences = re.split(r'(?<=[.!?])\s+|[ã€‚ï¼ï¼Ÿ]|(?<=ë‹¤)\s', text)
    return [s.strip() for s in sentences if s.strip()]

# =========================================================
# 2ï¸âƒ£ í‚¤ì›Œë“œ ê¸°ë°˜ Boost
# =========================================================
def boost_aspects(text, probs_dict):
    for aspect, kws in BOOST_KEYWORDS.items():
        if any(k in text for k in kws):
            probs_dict[aspect] = min(probs_dict.get(aspect, 0) + cfg["boost_value"], 1.0)
    return probs_dict

# =========================================================
# 3ï¸âƒ£ Phase-1 ì¸¡ë©´ íƒì§€
# =========================================================
def detect_aspects_multi(text, threshold=0.35):
    reg = ModelRegistry.get(
        cfg["phase1_model"],
        cfg["phase2_model"]
    )
    tok, model = reg["aspect_tokenizer"], reg["aspect_model"]   # âœ… dict ì ‘ê·¼
    device = reg["device"]

    sentences = split_sentences(text)
    total = {}

    print(f"\nğŸ§  [DEBUG] ë¬¸ì¥ë³„ ì¸¡ë©´ í™•ë¥  ë¡œê·¸")
    for s in sentences:
        inputs = tok(s, return_tensors="pt", truncation=True, padding=True).to(device)
        with torch.no_grad():
            logits = model(**inputs).logits
            probs = torch.sigmoid(logits).cpu().numpy()[0]
        detected = {ASPECTS[i]: float(probs[i]) for i in range(len(ASPECTS))}
        detected = boost_aspects(s, detected)
        for asp, prob in detected.items():
            print(f" - {asp:6s} | {s[:35]:35s} â†’ {prob:.3f}")
            if prob >= threshold:
                total[asp] = max(total.get(asp, 0), prob)
    return total

# =========================================================
# 4ï¸âƒ£ ë¶€ì • í‚¤ì›Œë“œ ë³´ì •
# =========================================================
def polarity_correction(text, aspect, label):
    if any(k in text for k in NEG_TRIGGERS) and aspect in ["ìµœì í™”", "ë°¸ëŸ°ìŠ¤"]:
        return "ë¶€ì •"
    return label

# =========================================================
# 5ï¸âƒ£ Phase-2 ê°ì • ë¶„ë¥˜
# =========================================================
def analyze_sentiment(aspect, text):
    reg = ModelRegistry.get(cfg["phase1_model"], cfg["phase2_model"])
    tok, model = reg["sent_tokenizer"], reg["sent_model"]
    device = reg["device"]        # âœ… dictì´ë¯€ë¡œ [] ì•„ë‹˜, ì•„ë˜ì„œ ìˆ˜ì • ë°˜ì˜
    ctx = text if aspect not in text else text[text.find(aspect)-20:text.find(aspect)+30]
    inputs = tok(f"[{aspect}] {ctx}", return_tensors="pt", truncation=True, padding=True).to(device)
    with torch.no_grad():
        probs = torch.softmax(model(**inputs).logits, dim=-1).cpu().numpy()[0]
    pos, neg = float(probs[1]), float(probs[0])
    if abs(pos-neg) < cfg["margin"]:
        label = "ì¤‘ë¦½"
    else:
        label = "ê¸ì •" if pos>neg else "ë¶€ì •"
    return {
        "aspect": aspect,
        "POS": pos,
        "NEG": neg,
        "label": polarity_correction(text, aspect, label)
    }

# =========================================================
# 6ï¸âƒ£ í†µí•© ë¦¬ë·° ë¶„ì„
# =========================================================
def analyze_review(text):
    detected = detect_aspects_multi(text)
    results = [analyze_sentiment(asp, text) for asp in detected.keys()]
    return {"text": text, "aspects": list(detected.keys()), "results": results}
